---
title: "R practice for stat test"
author: "ZHAI XINGYU"
date: "2024-06-17"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_depth: 3
    number_section: true
    latex_engine: xelatex
editor_options:
  markdown:
    wrap: 72
header-includes:
  - \usepackage{amsmath}
---



# ノンパラメトリック検定

## 符号検定

中央値がある値m_0に等しいかどうかを検定すること.

$H_0: m = m_0$
$H_1: m > m_0 \space (片側検定) \space or \space m \neq m_0 \space(両側検定)$

母集団から抽出した標本：$X_1, \dots, X_n$

検定統計量T：$T=\sum{I(X_i > m_0)}, \space T \sim Bin(n, \frac{1}{2})$


``` r
> # n=7
> # the pmf plot
> dbinom(0:7,7,0.5)
FALSE [1] 0.0078125 0.0546875 0.1640625 0.2734375 0.2734375 0.1640625 0.0546875
FALSE [8] 0.0078125
```

``` r
> plot(0:7, dbinom(0:7,7,0.5),ylab = "prob", xlab="T")
```

![](Rpract_files/figure-html/unnamed-chunk-1-1.png)<!-- -->

``` r
> # alpha=0.05, one side
> qbinom(0.05,7,0.5,lower.tail = F)
FALSE [1] 6
```

## 符号付き順位検定

検定統計量T：$T=\sum{i *I(X_i > 0)}, I \sim Ber(1/2)$
$E(iI)=i*1/2, V(iI)=i^2*1/4, E(T)=1/2\sum{i}=\frac{(1+n)n}{4}, v(T)=1/4 \sum{i^2}=\frac{n(n+1)(2n+1)}{6*4}$


``` r
> # n=7(sequence)
```



# 確率過程

参考：[数学的モデリングまとめ](https://manabitimes.jp/math/1057#4);[アクチュアリー会発行の教科書](https://www.actuaries.jp/examin/textbook/)


一般的に**確率過程(stochastic process)**とは、
様々な時刻で観察した対象を表現するモデルであり、
時間の経過とともに、対象が確率的にどのように変化・変動するかを確率変数で表現しているものです。

-  時間など，条件によって変化する確率変数の数理モデルである。

-  気温、株価や為替の変動、ブラウン運動などの粒子のランダムな運動を数学的に記述する模型（モデル）

    + 連続時間型モデル: 気温のように時間に対して連続的に変化していくもの
    
    + 離散時間型モデル: 毎日の保険事故発生件数のように一定の時間毎の数量を表すモデル

-  不規則過程(random process)


確率過程は、時刻を表すパラメーター$t$を用いて、確率変数の列$\{X_t\}$表します。

-  見本関数/標本関数(sample function): 確率過程$\{X_t\}$の一つの実現値$\{x_t\}$(tを引数とする関数)



**マルコフ過程(Markov process)**は現在の状態から確率的に次の状態が決まること、
**マルコフ連鎖(Markov chains)**はマルコフ過程のなかで*取りうる状態が有限*のもののことを言う。

-  ロシアの数学者:アンドレイ・アンドレエヴィチ・マルコフ(Andrey (Andrei) Andreyevich Markov)

-  未来の状態（の確率）が過去の状態によらず*現在の状態のみで決まる*ような確率過程

-  マルコフ連鎖:状態空間が離散的なマルコフ過程


**拡散過程(diffusion process)**とは*マルコフ過程*の特別な場合を指す確率過程で、
**ブラウン運動(ウィーナー過程)**とはその拡散過程の非常に特殊な場合を指します。

- *確率微分方程式(Stochastic differential equation)*の解として得られる確率過程$X_t$は拡散過程


そして拡散過程は、二つのパラメータ、*拡散係数(diffusion coefficient)*$\sigma(x,t)$と*ドリフト係数(drift coefficient)*$\mu(x,t)$によって特徴付けられます。

-  *拡散係数が1*、*ドリフト係数が0*のときをブラウン運動というのでした。





## マルコフ連鎖


<block>
マルコフ連鎖の定義:

マルコフ連鎖とは，

$$P(X_{t+1} | X_{t} , X_{t-1} , \dots,  X_1) = P(X_{t+1} | X_{t})$$
を満たすような確率変数の列$X_1, X_2, \dots$のこと。

-  $X_{t}$ によって$X_{t+1}$の傾向が決まる

-  $X_{t-1}$以前は$X_{t}$に影響しない
</block>


### 推移行列


-  初期分布/状態確率ベクトル

-  推移確率/遷移確率: $P(X_{t+1} | X_{t})$

注：この記事では時間的に均一（遷移確率が時刻によらない）なマルコフ連鎖を考えています。

-  推移/遷移確率行列: どの時点でも，次のステップで状態iから状態jに移る確率$q_{ij}$は一定(斉時的),
このような$q_{ij}$を(i，j)成分にもつような行列が推移確率行列Qです。

    + ij成分: iからjに推移する確率
    
    + 推移確率行列の各要素は0以上1以下です。
    
    + 推移確率行列のどの行も，行和は1です。

$$Q
=
\begin{bmatrix}
q_{11} & q_{12} & \dots  & q_{1j} & \dots  & q_{1N}\\
q_{21} & q_{22} & \dots  & q_{2j} & \dots  & q_{2N}\\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots\\
q_{i1} & q_{i2} & \dots  & q_{ij} & \dots  & q_{iN}\\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots\\
q_{N1} & q_{N2} & \dots  & q_{Nj} & \dots  & q_{NN}\\
\end{bmatrix}$$





-  状態空間:$X_t$がとりうる値の集合のこと。状態の全体, $S=\{1,2,3, \dots, N\}$

-  推移図/状態遷移図:１つ前の状態が決まると，次の状態へ移る確率が決まる







``` r
# create a dataframe
df1 <- data.frame(
  時点 = c(0,1,2,3,4,'...', 'n', 'n+1'),
  観測状態 = c(1,2,1,1,2,'...', 'i', 'j'),
  確率変数列 = c('X0=1', 'X1=2', 'X2=1', 'X3=1', 'X4=2', '...', 'Xn=i', 'Xn+1=j')
)

kable(df1, caption = 'マルコフ連鎖')
```



Table: マルコフ連鎖

|時点 |観測状態 |確率変数列 |
|:----|:--------|:----------|
|0    |1        |X0=1       |
|1    |2        |X1=2       |
|2    |1        |X2=1       |
|3    |1        |X3=1       |
|4    |2        |X4=2       |
|...  |...      |...        |
|n    |i        |Xn=i       |
|n+1  |j        |Xn+1=j     |

**NOTE:１つ前の状態が決まると，次の状態へ移る確率が決まる**

$$
P(X_4 = 2 | X_3 =2, X_2 = 1, X_1 = 2, X_0 = 1) = P(X_4 = 2 | X_3 =2) 
\rightarrow
１つ前の時点に関する条件だけで表せる
$$

**次の条件を満たすような確率変数列を離散時間のマルコフ連鎖と言います。**

${X_0, X_1, \dots, X_i}$

$$
P(X_{n+1} = j | X_{n} =i, X_{n-1} = i_{n-1}, X_{n-2} = i_{n-2}, \dots,  X_0 = i_0) = P(X_{n+1} = j | X_{n} =i)
$$

**斉時的: 条件付き確率が時点に依存しない**

$$
P(X_{n+1} = j | X_{n} =i) = q_{ij}
$$


**全確率の公式:時点nで1からNのどの状態にあったのか**

$$
P(X_{n+1} = j)= \sum_{1}^{N} {P(X_{n+1}=j|X_{n}=i)P(X_n=i)}
$$


略記

$$
P(X_n=i)=p_n(i)
$$

全確率の公式を次のように書き直すことができます。

$$
P(X_{n+1} = j)= \sum_{1}^{N} p_n(i)q_{ij}
$$


jは1からNまでの自然数のいずれかなので，そのすべてを列挙すると，次のように表せます。

$$
(p_{n+1}(1), p_{n+1}(2), \dots, p_{n+1}(j), \dots,  p_{n+1}(N))
=
(p_{n}(1), p_{n}(2), \dots, p_{n}(i), \dots,  p_{n}(N))
\begin{bmatrix}
q_{11} & q_{12} & \dots  & q_{1j} & \dots  & q_{1N}\\
q_{21} & q_{22} & \dots  & q_{2j} & \dots  & q_{2N}\\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots\\
q_{i1} & q_{i2} & \dots  & q_{ij} & \dots  & q_{iN}\\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots\\
q_{N1} & q_{N2} & \dots  & q_{Nj} & \dots  & q_{NN}\\
\end{bmatrix}
$$




### チャップマン–コルモゴロフ方程式

定理: マルコフ連鎖の推移確率行列について**「推移確率行列のn乗」** $Q^n$と**「n回の遷移の確率」**$Q^{(n)}$が
対応するという性質が成り立ちます。

-  n時刻経過に対する推移確率行列を$Q^{(n)}$と書くことにします。

-  つまり，$P(X_{t+n}=j|X_{t}=i)$をij成分に持つ行列を$Q^{(n)}$とします。

-  $Q^{(n)}=Q^n$


$$状態確率ベクトル:p_{t+n}=(初期分布:p_t)[推移確率行列:Q]^n$$

-  推移確率行列が対角化可能な行列であれば，固有値でQのn乗を手計算でも求めることができる



**チャップマン–コルモゴロフ方程式(Chapman-Kolmogorov equation)**

上記の定理より，$Q^{(n+m)}=Q^{(n)}Q^{(m)}$が成立します。

-  n時刻ぶんの遷移の様子$Q^{(n)}$とm時刻ぶんの遷移の様子$Q^{(m)}$が分かれば、
(n+m)時刻ぶんの遷移の様子$Q^{(n+m)}$も分かります。



### 定常分布

nが十分に大きければ，
n日後の状態確率ベクトルと(n＋１)日後の状態確率ベクトルはほぼ等しくなるので，
最終的な*状態確率ベクトル*をπとして，次の式が成り立つことになりそうです。

$\pi = \pi A$

このようなπを*定常分布*と言います。

*推移確率行列A*をかけても変化しないような*状態確率ベクトル$\pi$*です。


<block>
推移確率行列A

$$
A=
\begin{bmatrix}
a_1 & a_2 \\
b_1 & b_2
\end{bmatrix}
$$
定常分布$\pi = (a,b)$を求めます

$$
(a,b)
=
(a,b)
\begin{bmatrix}
a_{1} & a_{2} \\
b_{1} & b_{2}
\end{bmatrix}
$$
</block>


#### 定常分布の存在と一意性

既約: すべての状態の間で有限回の移動で移り合うことができるマルコフ連鎖

一般に，既約な有限マルコフ連鎖は*ただ１つの定常分布をもつ*ことが知られています。




### 推移行列の応用


従業員の出社・病欠モデル:

推移確率:

1.  本日は健康で、昨日も健康な人が、次の日に出社する確率は 0.99。

2.  本日は健康だが、昨日は病欠の人が、次の日に出社する確率は 0.95。

3.  本日は病欠だが、昨日は健康だった人が、次の日に出社する確率は 0.80。

4.  本日も昨日も病欠の人が、次の日に出社する確率は、0.60。


以下のとおり*４つの状態*でモデル化：

1.  状態 1：本日は健康で、昨日も健康

2.  状態 2：本日は健康だが、昨日は病欠

3.  状態 3：本日は病欠だが、昨日は健康

4.  状態 4：本日も昨日も病欠


このモデルの推移確率行列:

$$
P=
\begin{bmatrix}
0.99 & 0    & 0.01  & 0    \\
0.95 & 0    & 0.05  & 0    \\
0    & 0.80 & 0     & 0.20 \\
0    & 0.60 & 0     & 0.40 \\
\end{bmatrix}
$$

本日も昨日も健康な従業員が、1 週間後に病欠となっている確率:

$P^{(7)}$の(1,3)成分と(1,4)成分の合計であるので、0.013675 です。


$$
P^{(7)}=
\begin{bmatrix}
0.99 & 0    & 0.01  & 0    \\
0.95 & 0    & 0.05  & 0    \\
0    & 0.80 & 0     & 0.20 \\
0    & 0.60 & 0     & 0.40 \\
\end{bmatrix}^7
=
\begin{bmatrix}
0.976086 &  0.010239   & 0.010271  &  0.003404   \\
0.975770 &  0.010426   & 0.010286  &  0.003518   \\
0.972705 &  0.012250   & 0.010426  &  0.004619   \\
0.969998 &  0.013856   & 0.010552  &  0.005594   \\
\end{bmatrix}
$$


## ブラウン運動


### マルコフ連鎖n

1/n秒に１回コインを投げ、表は$+\frac{1}{\sqrt{n}}$点、裏は$-\frac{1}{\sqrt{n}}$点

<block>
**例題： マルコフ連鎖nにおいて、t秒間に得られる得点の期待値および分散**

ただし、$t=t' + t''(t' \times n は整数かつ 0 \leq t''< \frac{1}{n})$とします。

解答：　１回コインを投げて得られる得点を X で表し、t 秒間に得られる得点を S で表すと、

$$E(X)=\frac{1}{\sqrt{n}} \times \frac{1}{2} - \frac{1}{\sqrt{n}} \times \frac{1}{2}=0$$

$$E(X^2)=(\frac{1}{\sqrt{n}})^2 \times \frac{1}{2} + (\frac{1}{\sqrt{n}})^2  \times \frac{1}{2}=\frac{1}{n}$$

$$V(X)=E(X^2)-(E(X))^2=\frac{1}{2}=\frac{1}{n}$$

1/n秒に１回コインを投げ、t 秒間にコイントスは$t' \times n$回行われるので、

$$S=X_1 + \dots + X_{nt'}$$

$$E(S)=0, V(S)=t' n \times V(X) = t' $$
ここで *nを無限大*まで大きくすることを考えます。
すると、それはある確率過程となります。
その確率過程は**ブラウン運動**とよばれる確率過程です。
</block>


### ブラウン運動（Brownian motion）


以下を満たす確率過程X($\{X_t\}:X=(X_t)_{t>0} \space t時刻の位置、上記のS$)と言います。

1.  連続性：$X_t$の見本関数/パスはtに関する連続関数

2.  独立増分性：$0 \leq s < t \leq u < v \rightarrow X_t - X_s と X_v - X_uは独立$

    + または、次のような任意の時間の分割$0 = t_0 < t_1 < \dots < t_{n-1} < t_n$に対して，
    次のようなn個の増分はすべて互いに独立：$X_{t_i} - X_{t_{i-1}}$
    
    + 注：増分独立、$X_{t}$ と $X_{s}$ は独立ではないことに注意しましょう。

3.  定常増分性： $X_{s+t}-X_tとX_s同じ分布に従う$

    + 増分は期待値，分散が時間の幅(s+t-t=s)に比例する正規分布に従う


\[
\textbf{Theorem:}
任意の t > s \geq 0に対して，
X_t をブラウン運動とするとき、増分 X_t-X_s は、期待値E(X_t-X_s)・分散V(X_t-X_s)の正規分布に従う。\\
X_t-X_s \sim N[E(X_t-X_s), V(X_t-X_s)] = N[\mu (t-s), {\sigma}^2 (t-s)]
\]



一般的なブラウン運動は，*$\mu$と$\sigma$というパラメータ*を使って，次のように表せます。

$$\sigma X_t + \mu t \sim N(\mu t, {\sigma}^2 t)$$

-  $\mu$: ドリフト係数と呼ばれるもので，トレンドを表しています。

    + $\mu > 0$ならば，期待値と分散は時間が経過するほど増加することがわかります。

-  $\sigma$: 拡散係数と呼ばれるもので，$\mu t$のまわりのばらつき方を決めるパラメータです。



ただし，$X_t$と$X_s$は独立ではないことに注意しましょう。

$$cov(X_t, X_s)=cov(X_t - X_s + X_s, X_s)
=cov(X_t - X_s, X_s) + cov(X_s, X_s)
=0 + V(X_s)={\sigma}^2 s \space (増分独立により)$$


ブラウン運動は正規分布に対応する確率過程であり、正規分布がガウス分布とも呼ばれることから、
**ガウス過程（Gaussian process）**とも呼ばれます。


### 標準ブラウン運動/ウィーナー過程

ブラウン運動がさらに次の条件を満たすときに、
**標準ブラウン運動（standard Brownian motion）**または**ウィーナー過程（Wiener process）**といいます。

4.  $X_0=0$

5.  $E(X_t)=0$

6.  $V(X_t)=t$

なお、ウィーナー過程($X_t \sim N(0,t)$)は、標準正規分布に対応する確率過程です。


-  $\mu=0, \sigma=1$が成り立つ場合を標準ブラウン運動と言います。




### パラメータの推定


株価など，ブラウン運動を使ってモデル化したい現象があったときに，
$\mu$や$\sigma$といったパラメータを推定する必要があります。
そのための方法として，*等しい時間間隔(独立増分性と定常増分性を利用)*で
高頻度にデータを観測する方法があります。


一般的に，一定の時間間隔をデルタ$\Delta=t/n, k=\{1, \dots,n\}$とした場合には，
となり合う時点間の増分は次の正規分布に従います。

$$
S_k = X_{k \Delta} - X_{(k-1) \Delta} \sim N(\mu \Delta, {\sigma}^2 \Delta)
$$

上の正規分布のパラメータを最尤法(MLE)で推定するとすれば，
母平均の最尤推定量は標本平均だったので，次の式になります。

$$
\hat{\mu \Delta} = \bar{S_k}=\frac{1}{n} \sum_{k=1}^{n}{S_k}\\
\hat{{\sigma}^2 \Delta} = \frac{1}{n} \sum_{k=1}^{n} (S_k - \bar{S_k})^2 = 
\frac{1}{n} \sum_{k=1}^{n}{S_k^2} - (\frac{1}{n} \sum_{k=1}^{n}{S_k})^2
$$

### 株価モデル 

ウィーナー過程は、大変扱いやすい（計算しやすい）という性質をもっており、
金融工学等の分野でよく用いられます。


-  例えば、*ブラック・ショールズ式（The Black-Scholes formula）*と呼ばれるオプションのプライシング公式も、
このブラウン運動を元に計算を行っています


## ポアソン過程

### 計数過程

推定・検定で最も重要な確率分布が正規分布であるように，
**連続時間確率過程**の中で最も重要だと言ってもいいのが**ポアソン過程**です。

-  ポアソン過程は，*一定の時間内*にランダムな*イベントが起きる回数*をモデル化した連続時間確率過程です。

-  十分に多くの*計数過程*$\{N_t\}$を合成すると，ポアソン過程で近似できるという性質があります。

    + 計数過程(counting process): 何らかの事象の発生回数を数える確率過程

-  *待ち行列理論(Queuing Theory)*などの幅広い応用を持ちます。

    + コンピュータシステム： プロセス処理

    + ネットワークシステム： パケット通信



**数学的に計数過程の定義**

連続時間型の確率過程が計数過程であるとは、以下の３つの条件を満たすことをいいます。

1.  $N_0=0$

2.  $N_t$の標本関数は非負の整数値で、t に関し単調増加。

3.  $N_t$の標本関数は、右連続。



この計数過程(時間幅tの中で)に対し、以下の３条件を仮定する:

1.  独立増分性:

    + 加法過程(additive process)/独立増分過程: 独立増分性を満たす確率過程
    
    + 加法過程は、マルコフ過程となっています。

    + e.g. たまたまある時間帯に通った車が多かったとしても、
    その後から来る車が多くなったりまたは少なくなったりしない。

2.  定常増分性：時点によって変化せず一定

    + 定常過程（stationary process）
    
    +  e.g.通り過ぎる車の台数は、時刻ではなく時間の幅のみに依存することを意味している。
    

3.  同一時刻に２つ以上のイベントが発生することはない/確率は十分に小さい。

    + 同一時刻に２台以上の車が通り過ぎることはない。


上記の１から３の条件を満たす計数過程を**ポアソン過程（Poisson process）**といいます。



### 二項分布とポアソン分布

区間$[0,t]$でイベントが起こる回数が$k$回である確率を式で表してみましょう。

1.  区間$[0,t]$微小な時間幅に分け(時刻０から時刻tまでを$n$等分し，それぞれの微小区間の時間幅を$\Delta t$)，
１個の微小区間で*２回以上のイベントは起こらない*ようにできるというのがポアソン過程の前提です。


2.  単位時間あたりの事象の*平均的な生起回数*を$\lambda$ とすると，
微小区間の時間幅$\Delta t$の中での事象の平均的な生起回数は$\lambda \Delta t$となります。


3.  この微小区間においては，事象が１回起きるか起きないかのベルヌーイ試行とみなすことができます。
ベルヌーイ分布にしたがう確率変数の期待値は成功確率pに等しいことから，
平均的な生起回数$\lambda \Delta t$は*確率とみなす*ことができます。

-  微小区間$\Delta t$tの間に事象は発生する確率

$$Ber(\lambda \Delta t) \rightarrow Ber(p), \space 0 \leq \lambda \Delta t \leq 1$$


4.  n個の微小区間のうち，k個で*１回ずつ事象*が生起する確率は，二項分布を使って次の式で表せます。


$$X \sim Bin(n,p) \rightarrow Bin(n, \lambda \Delta t), \Delta t=t/n$$
-  つまり、時間間隔[0,t]で、事象が k 回発生する確率$p_k(t)$

$$P(N_t=k)=\binom{n}{k}  p^k (1-p)^{n-k}, p=\lambda \Delta t=\frac{\lambda t}{n}$$

$$P(N_t=k)=\frac{n!}{k!(n-k)!} (\frac{\lambda t}{n})^k (1- \frac{\lambda t}{n})^{n-k}$$


$$P(N_t=k)= \frac{(\lambda t)^k}{k!} \times \frac{n!}{n^k (n-k)!} \times (1- \frac{\lambda t}{n})^{n-k}$$


$n \rightarrow \infty$の極限:

$$\frac{n!}{n^k (n-k)!} \rightarrow 1$$

$$(1- \frac{\lambda t}{n})^{n-k}=(1- \frac{\lambda t}{n})^n (1- \frac{\lambda t}{n})^{-k} \rightarrow exp(- \lambda t) \times 1 =exp(- \lambda t)$$

よって，$n \rightarrow \infty, \Delta t \rightarrow 0, t = n \Delta t$の極限をとると，
区間 [0, t] で事象が k 回起こる確率$p_k(t)$は次の式で表せます。


$$P(N_t=k)= \frac{(\lambda t)^k e^{-\lambda t}}{k!}$$


ポアソン分布の性質から期待値と分散は次の式で表せます。

$$E(N_t)=V(N_t)=\lambda t$$



#### ポアソン分布の応用


１時間(単位時間)あたり平均8台の車が通り過ぎるとき、
30分で3台の車が通り過ぎる確率:

$$\lambda=8/h, \\
\lambda t = 8 \times 0.5 = 4 \\
P(X=3)=\frac{(\lambda t)^k e^{-\lambda t}}{k!}=\frac{(4)^3 e^{-4}}{3!} \simeq 0.1953668$$


``` r
# the density of Poisson Distribution
# dpois(x, lambda, log = FALSE) ;lambda=means at t
dpois(3, lambda = 8*0.5, log = F) #0.1953668
```

```
## [1] 0.1953668
```



$$\lambda=8 \rightarrow １時間(単位時間)あたり平均8台の車が通り過ぎる \rightarrow 平均的な通り過ぎる間隔は\frac{1}{8}時間になる \rightarrow \lambda=8の指数分布の期待値が\frac{1}{8}$$



### ポアソン過程と指数分布

ポアソン過程は、*ポアソン分布*に対応する確率過程です。
ポアソン過程を、数学的な表現で記載すると、以下のとおりとなるます。

1.  独立増分性： $0 \leq s <t \leq u < v \rightarrow N_t - N_sとN_v - N_uは独立$

2.  定常増分性： $N_{s+t} - N_t とN_tは同じ分布に従う。$

    + 時点sに関係なく，時間幅がtであれば，イベントが起こる回数は同じ確率分布にしたがう

3.  $P(N_{t+h} - N_t \geq 2) = o(h), \lim_{h \to 0} \frac{o(h)}{h}=0$


*区間[0,t]*で注目している事象が起こる回数を$N_t$として，ポアソン過程$N= (N_t)_{t \geq 0}$ が以下の条件を満たすとき，強度$\lambda$のポアソン過程であると言います。

-  任意の$t>0, s \geq 0$に対して，次の式が成り立つ。

$$P(N_{s+t} - N_t = k)=\frac{(\lambda t)^k e^{-\lambda t}}{k!}, (k=0,1,2, \dots)$$



強度$\lambda$のポアソン過程において、*時間T内で事象が一度も発生しない*確率$p(T)=P(t>T)$を考えます。

-  つまり、事象が発生する*時間間隔tがT以上*となる確率($N_t=k=0, P_0(T)$)に同値。


$$p(T)=P(t>T)=P_0(T)=P(N_T = 0)= \frac{exp(- \lambda T) (\lambda T)^0}{0!}=exp(- \lambda T), \space T>0$$


**時間t内で事象が発生する確率**$q(T)$


$$q(T)=P(t \leq T)=1-p(T)=1-exp(- \lambda T)$$
これは**指数分布の累積分布関数**$F(t)$に一致しているので、
*Tは指数分布*にしたがうことがわかります。


つまり、最初のイベントが起きる時刻と$T_1$とすると，$T_1$は指数分布にしたがうことがわかります。
そして，それは最初のイベントまでの時間だけではなく，
最初のイベントが起きてから２回目のイベントが起きるまでの時間$T_2-T_1$も指数分布にしたがい，
それ以降$(T_3 - T_2), \dots, (T_{i} - T_{i-1})$も同様です。



そこで，となり合うイベントの時間の間隔$T_{i} - T_{i-1}$を表す確率変数を$W_i$と表すことにすると，
独立に同一の指数分布(i.i.d)にしたがいます。

$$W_i \sim Exp(\lambda), i=1,2, \dots$$

次に，n回のイベントの発生時刻を表す確率変数$T_n$を次の式で定めます。

$$T_n = W_1 + W_2 + \dots + W_n, T_0=0$$
このとき，$N_t$(時刻tまででイベントが何回起きたか)を次の式で定めると， 
確率過程$N=(N_t)_{t \geq 0}$は強度$\lambda$のポアソン過程になります。

$$N_t = \max\{n | T_n \leq t \}$$




-  指数分布($T \sim Exp(\lambda)$)の分布関数(CDF, $P(t \leq T)$)

$$F(t) = 1 - exp(- \lambda t)$$

-  確率密度関数(PDF)

$$f(t)=\lambda exp(- \lambda t) $$


### パラメータの推定

工場で生産されているある製品について，
不良品率が一定であれば，*不良品の個数はポアソン過程*とみなすことができます。
このときのポアソン過程の生起率/強度$\lambda$はどのように求めたらよいでしょうか。


イベントが起きた時刻(ポアソン過程$N(t)$のジャンプ時間)を，$T_1, T_2, T_3, \dots$と表すと，
となり合うイベントの時間の間隔$W_i=T_i-T_{i-1}$は独立に同一の指数分布にしたがいます。


$$\hat{\lambda}_{MLE} = \frac{n}{\sum_{i=1}^{n}{W_i}}=\frac{n}{T_n}$$


イベントが起きた時刻を観測してパラメータを推定する方法は，
場合によっては手間がかかるかもしれません。
そこで，より簡便な方法として，
決まった時間間隔$\Delta t$ごとに観測して，イベントが起きた回数を記録する方法があります。
この方法でも上と同じ最尤推定量を導くことができます。


### 複合ポアソン過程

ポアソン過程はジャンプ 1 の場合であったが，一般に*ランダムな幅のジャンプ(確率変数)*も考えられます。

-  時刻$t$までの入金総額$X_t$：銀行の窓口に入金にやってくる人の数$N(t)$の分布がポアソン分布に従ったとしても，その入金額は必ずしも一定とは限らなりません。時刻$t$までの入金総額$X(t)$とあらわすと，複合ポアソン過程によってモデル化することができます。

-  時刻$t$までの販売額の合計$X_t$：ある商品の販売サイトの購入ボタンのクリック数$N(t)$がポアソン過程にしたがっています。１回のクリックによって，顧客が何円分の商品を購入するかは確率的に変動するものとして，それを$Y_k,(k=1, 2, \dots, N(t))$いう確率変数で表しています。このときの販売額の合計$X(t)=Y_1 + \dots + Y_{N(t)}$に対応するのが複合ポアソン過程です。


#### 定義

$N(t)$を生起率/強度$\lambda$のポアソン過程,
$Y_1, T_2, \dots$は独立同分布確率変数列で$N(t)$とも独立であるとします。
これらによって定義される確率過程を**複合ポアソン過程**といいます。

$$X(t)=\sum_{k=1}^{N(t)}{Y_k}$$

-  $X(0)=0$

-  $右連続$

-  $P(Y_i=1)=1$であるときは，通常の生起率$\lambda$のポアソン過程です。($E(Y)=1, V(Y)=0$)

-  $E(N(t))=V(N(t))=\lambda t$


-  $E(X(t))=E(N_t) E(Y)$

    + 通常のポアソン過程は$E(Y)=1$なので，$E(X(t))=E(N_t)$

-  $V(X(t))=\{E(Y)\}^2 V(N_t) + V(Y) E(N_t)$

    + 通常のポアソン過程は$V(Y)=0, E(Y)=1$なので，$V(X(t))=V(N_t)$


#### 期待値と分散の計算


$E(Y_k)=\mu, V(Y_k)=\sigma ^2$

**期待値**

$N_t$で条件付き分布($N_t$と固定すると，内側の期待値が計算できます):

$$E(X_t)=E[E(X_t|N_t=n)]$$
内側の期待値:

$$E(X_t|N_t=n)=E(Y_1 + Y_2 + \dots + Y_n | N_t = n)= \sum_{k=1}^{n}{E(Y_k|N_t=n)} =nE(Y)$$
この結果を使って，$E(X_t)$の期待値を求めると，次のようになります。


$$E(X_t)=E[E(X_t|N_t=n)]=\sum_{n=0}^{\infty}{E(X_t|N_t=n)P(N_t=n)}=E(Y) \sum_{n=0}^{\infty}{n P(N_t=n)}=E(Y)E(N_t)=\mu \lambda t$$

**分散**

$$E(X_t^2|N_t=n)=V(X_t|N_t=n)+\{E(X_t|N_t=n)\}^2=nV(Y)+n^2 \{E(Y) \}^2$$


$$E(X_t^2)= E[E(X_t^2|N_t=n)]=\sum_{n=0}^{\infty}{E(X_t^2|N_t=n)P(N_t=n)}=\sum_{n=0}^{\infty} \{nV(Y)+n^2E(Y)^2 \} P(N_t=n)=V(Y) \sum_{n=0}^{\infty}{n P(N_t=n)} + \{E(Y)\}^2 \sum_{n=0}^{\infty}{n^2 P(N_t=n)}=V(Y)E(N_t) + \{E(Y)\}^2 E(N_t^2)$$



$$V(X_t)=E(X_t^2)-\{E(X_t)\}^2=V(Y)E(N_t) + \{E(Y)\}^2 E(N_t^2) - \{E(Y)\}^2 E(N_t)^2=V(Y)E(N_t) + \{E(Y)\}^2 V(N_t)$$



$$V(X_t)=\sigma^2 \lambda t + \mu^2 \lambda t =\lambda t (\mu^2 + \sigma^2)$$


注意. $N$を非負整数値確率変数，$Y$をi.i.d.確率変数列で，$N$と$Y$が独立であるとします。
このとき，$X=\sum_{k=1}^{N}{Y_k}$とおくと，Waldの等式が成り立ちます。

$$E(X)=E(N)E(Y_1)$$

#### 分散と期待値の応用


**例題： 複合ポアソン過程において、t時間後の入金総額の期待値と分散**


１時間あたりに会計を行う客の人数が平均40人のポアソン過程であるとみなすことができ，
それぞれの客の支払い額は独立に，平均1000円，標準偏差500円の同一の確率分布にしたがうものとする。
１日の10時間の営業での売上の平均と標準偏差を求めなさい。


$$\lambda=40, t=10, E(Y)=\mu=1000, V(Y)=\sigma ^2 =500^2$$
$$E(X_t|t=10)=E(N_t|t=10)E(Y)=\lambda t \mu$$
$$V(X_t|t=10)= \{E(Y)\}^2 V(N_t)+ V(Y)E(N_t) =\lambda t (\mu^2 + \sigma^2)$$
$$\sigma_{X_t|t=10}=\sqrt{V(X_t|t=10)}$$
